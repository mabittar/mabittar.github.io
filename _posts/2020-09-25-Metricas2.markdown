---
layout: post
title: Métricas para Avaliação de modelos de Machine Learning
date: 2020-09-25 00:00:00 +0300
description: Avaliações e Comparação de modelos de Machine Learning # Add post description (optional)
img: curve.jpg # Add image post (optional)
tags: [Machine Learning, Python, Model, Metrics] # add tag
---

Essa é a segunda parte do [post]({% post_url /_post/2020-08-26-Metricas %}) referente a métricas para avaliação dos modelos de Machine Learing.
No primeiro post foi abordado alguns temas sobre TP, TN, FP, FN, acurácia, precisão e matriz de confusão utilizadas para que possamos comparar os resultados obtidos em diversos modelos matemáticos.

*"Uma métrica de avaliação quantifica a performance de um modelo de machine learning."* `Jason Brownlee`

Entretanto quando estamos lidando com modelo de Machine Learning podemos observar também a performance de aprendizado com tempo e experiência de utilização do modelo. Neste post, você vai descobrir o que são as curvas de aprendizado e como elas são utilizadas no diagnóstico de comportamento dos modelos de Machine Learning.

Escolher o modelo de Machine Learning a ser utilizado na solução de um problema é tão desafiador quando definir a métrica apropriada.

# ROC

A sigla **ROC** significa *“Receiver Operating Characteristic”* e demonstra a capacidade do modelo em distinguir corretamente duas categorias, portanto utilizado para classificação.  Para plotarmos a curva ROC é necessário calcular as probabilidades de cada observação pertencer a classe em questão.

Uma vantagem da curva ROC é podermos observar o ponto de corte (onde o modelo fica estável) e otimizar o desempenho do mesmo, economizando recurso.

O ROC possui os seguintes parâmetros:

 - Sensibilidade
 - Especificidade

A curva ROC traça a Sensibilidade (Taxa de Verdadeiros Positivos) x Especificidade (Taxa de Falsos Positivos)


![](https://scikit-learn.org/stable/_images/sphx_glr_plot_roc_0011.png)

# AUC

Já a **AUC** (*area under the ROC curve*) ou área sobre a curva ROC é a derivada da ROC. 

É uma tentativa de resumir a curva ROC em um único valor.

O valor de AUC varia entre 0 e 1,0 e quanto maior for o AUC melhor é a capacidade do modelo em prever a categoria correta.

![AUC característico. Fonte: flai.com.br](https://www.flai.com.br/wp-content/uploads/2020/06/roc.png)



# Conclusão

Métricas de avaliação desempenham um papel crucial orientando o modelo de aprendizado, assim como, classificando a sua performance.

Nesta série de posts foram abordadas as métricas clássicas para avaliação de desempenho do modelo gerado. Tais métricas funcionam muito bem para a maioria dos problemas e são largamente utilizadas, inclusive como um ponto de partida para modelos mais avançados.
Tenha em foco que uma métrica de avaliação deve caputrar o que você e seus stakeholders avaliam como desejado para o modelo e suas previsões, o que torna a definição da métrica a ser utilizada um desafio e tanto.


# Fontes

 - Documentação oficial: [Scikit Leaning](https://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics)
 - ML Wiki: [Link](http://mlwiki.org/index.php/ROC_Analysis)
 - How to use Learning Curves to Diagnose Machine Learning Model Performance: [Link](https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/)
 - 10 questões de entrevistas: [Link](https://www.flai.com.br/10-questoes-de-data-science-em-entrevistas-de-emprego-da-microsoft/) 